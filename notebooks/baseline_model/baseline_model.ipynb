{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Proposed Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Variables</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the dataset\n",
    "dataset_dir = './12K-Sorted'\n",
    "\n",
    "# Label map\n",
    "label_map = {\n",
    "    'Block': 0,\n",
    "    'Interjection': 1,\n",
    "    'NoStutter': 2,\n",
    "    'Prolongation': 3,\n",
    "    'SoundRepetition': 4,\n",
    "    'WordRepetition': 5\n",
    "}\n",
    "\n",
    "# Reversed Label map\n",
    "reversed_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Preprocessing\n",
    "duration = 3.0  # seconds\n",
    "sampling_rate = 16000  # Hz\n",
    "n_mels = 128\n",
    "n_mfcc = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Retrieving audio files and their labels</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_audio_files_and_labels(dataset_dir):\n",
    "    audio_files = []\n",
    "    for label_dir in os.listdir(dataset_dir):\n",
    "        if label_dir in label_map:\n",
    "            label = label_map[label_dir]\n",
    "            class_dir = os.path.join(dataset_dir, label_dir)\n",
    "            for audio_file in os.listdir(class_dir):\n",
    "                audio_path = os.path.join(class_dir, audio_file)\n",
    "                audio_files.append((audio_path, label))\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_audio(audio_path, target_length=94):\n",
    "    try:\n",
    "        audio, sr = librosa.load(audio_path, sr=sampling_rate)\n",
    "\n",
    "        if len(audio) != int(duration * sampling_rate):\n",
    "            print(f\"Audio file {audio_path} is not exactly {duration} seconds.\")\n",
    "            return None\n",
    "\n",
    "        log_mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "        log_mel_spectrogram = librosa.power_to_db(log_mel_spectrogram, ref=np.max)\n",
    "\n",
    "        if log_mel_spectrogram.shape[1] < target_length:\n",
    "            # Pad with zeros if too short\n",
    "            pad_width = target_length - log_mel_spectrogram.shape[1]\n",
    "            log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        elif log_mel_spectrogram.shape[1] > target_length:\n",
    "            # Trim if too long\n",
    "            log_mel_spectrogram = log_mel_spectrogram[:, :target_length]\n",
    "\n",
    "        return log_mel_spectrogram.T # (time_steps, features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {audio_path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing (single file)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_concat_audio(audio_path, target_length=94, sr=sampling_rate):\n",
    "    try:\n",
    "        audio, _ = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "        if len(audio) != int(duration * sampling_rate):\n",
    "            print(f\"Audio file {audio_path} is not exactly {duration} seconds.\")\n",
    "            return None\n",
    "        \n",
    "        log_mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "        log_mel_spectrogram = librosa.power_to_db(log_mel_spectrogram, ref=np.max)\n",
    "\n",
    "        if log_mel_spectrogram.shape[1] < target_length:\n",
    "            # Pad with zeros if too short\n",
    "            pad_width = target_length - log_mel_spectrogram.shape[1]\n",
    "            log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        elif log_mel_spectrogram.shape[1] > target_length:\n",
    "            # Trim if too long\n",
    "            log_mel_spectrogram = log_mel_spectrogram[:, :target_length]\n",
    "\n",
    "        return log_mel_spectrogram.T # (time_steps, features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {audio_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load and preprocess dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_dataset(audio_files):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for audio_path, label in audio_files:\n",
    "        log_mel = preprocess_audio(audio_path)\n",
    "        if log_mel is not None:\n",
    "            x.append(log_mel)\n",
    "            y.append(label)\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Probability Distribution Plotting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_probability_distribution(probability_distribution):\n",
    "    class_labels = [reversed_map[i] for i in range(len(probability_distribution))]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(class_labels, probability_distribution, color='skyblue')\n",
    "    plt.xlabel('Stutter Types')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Probability Distribution for Each Stutter Type')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Layer Normalization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, features: int, eps: float = 1e-6) -> None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(features))\n",
    "        self.bias = nn.Parameter(torch.zeros(features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        alpha = self.alpha.to(x.device)\n",
    "        bias = self.bias.to(x.device)\n",
    "\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        return alpha * (x - mean) / (std + self.eps) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2 x Conv1D Layer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class Conv1DBlock(nn.Module):\n",
    "    def __init__(self, feature_size: int, filter_size: int, output_size: int, kernel_size_1: int, kernel_size_2) -> None:\n",
    "        super().__init__()\n",
    "        # First Conv1D Layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=feature_size, out_channels=filter_size, kernel_size=kernel_size_1, padding='same')\n",
    "        self.norm = nn.LayerNorm(filter_size)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "        # Second Conv1D Layer\n",
    "        self.conv2 = nn.Conv1d(in_channels=filter_size, out_channels=output_size, kernel_size=kernel_size_2, padding='same')\n",
    "        self.norm2 = nn.LayerNorm(output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Conv1D -> LayerNorm -> GELU -> Dropout\n",
    "        x = self.conv1(x.transpose(1, 2))  # Conv1D expects (batch, channels, timesteps), so transpose\n",
    "        x = self.norm(x.transpose(1, 2))  # LayerNorm expects (batch, timesteps, features), so transpose back\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Repeat for second Conv1D layer\n",
    "        x = self.conv2(x.transpose(1, 2))\n",
    "        x = self.norm2(x.transpose(1, 2))\n",
    "        return self.activation(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sinusoidal Positional Encoding</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, timesteps: int, d_model: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.timesteps = timesteps\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Create a matrix of shape (timesteps, d_model)\n",
    "        pe = torch.zeros(timesteps, d_model)\n",
    "        # Create a vector of shape (timesteps, 1)\n",
    "        position = torch.arange(0, timesteps, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(1000.0) / d_model))\n",
    "        # Apply the sin to even positions\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0) # (1, timesteps, d_model)\n",
    "\n",
    "        # Register as buffer so that the tensor will be saved to the file but not as a learned params\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # self.pe = self.pe.to(x.device)  \n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feed Forward Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff) # W1 and B1\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model) # W2 and B2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch, timesteps, d_model) --> (batch, timesteps, d_ff) --> (batch, timesteps, d_model)\n",
    "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Multi-head Self Attention Layer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        assert d_model % h == 0, f\"d_model {d_model} is not divisible by h\"\n",
    "        \n",
    "        self.d_k = d_model // h\n",
    "        self.w_q = nn.Linear(d_model, d_model) #Wq\n",
    "        self.w_k = nn.Linear(d_model, d_model) #Wk\n",
    "        self.w_v = nn.Linear(d_model, d_model) #Wv\n",
    "\n",
    "        self.w_o = nn.Linear(d_model, d_model) #Wo\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query, key, value, mask, dropout: nn.Dropout):\n",
    "        d_k = query.shape[-1]\n",
    "\n",
    "        # (batch, h, timesteps, d_k) --> (batch, h, timesteps, timesteps)\n",
    "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
    "        attention_scores = attention_scores.softmax(dim = -1) # (batch, h, timesteps, timesteps)\n",
    "        if dropout is not None:\n",
    "            attention_scores = dropout(attention_scores)\n",
    "\n",
    "        return (attention_scores @ value), attention_scores\n",
    "\n",
    "    def forward(self, q, k, v, mask):\n",
    "        query = self.w_q(q) # (batch, timesteps, d_model) --> (batch, timesteps, d_model)\n",
    "        key = self.w_k(k) # (batch, timesteps, d_model) --> (batch, timesteps, d_model)\n",
    "        value = self.w_v(v) # (batch, timesteps, d_model) --> (batch, timesteps, d_model)\n",
    "\n",
    "        # (batch, timesteps, d_model) --> (batch, timesteps, h, d_k) --> (batch, h, timesteps, d_k)\n",
    "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
    "\n",
    "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
    "\n",
    "        # (batch, h, timesteps, d_k) --> (batch, timesteps, h, d_k) --> (batch, timesteps, d_model)\n",
    "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
    "\n",
    "        # (batch, timesteps, d_model) --> (batch, timesteps, d_model)\n",
    "        return self.w_o(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Residual Connection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, features: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = LayerNormalization(features)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Encoder</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.feed_foward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\n",
    "    \n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n",
    "        x = self.residual_connections[1](x, self.feed_foward_block)\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNormalization(features)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Decoder</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.self_attention_block = self_attention_block\n",
    "        self.cross_attention_block = cross_attention_block\n",
    "        self.feed_forward_block = feed_forward_block\n",
    "        self.residual_connections = nn.ModuleList(ResidualConnection(features, dropout) for _ in range(3))\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
    "        x = self.residual_connections[1](x, lambda x: self.self_attention_block(x, encoder_output, encoder_output, src_mask))\n",
    "        x = self.residual_connections[2](x, self.feed_forward_block)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        self.norm = LayerNormalization(features)\n",
    "\n",
    "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Classification Layer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, d_model: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Take the mean of the encoder outputs over the sequence dimension\n",
    "        x = x.mean(dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Baseline Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, conv: Conv1DBlock,pos_enc: PositionalEncoding, encoder: Encoder, classifier: ClassificationHead) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = conv\n",
    "        self.pos_enc = pos_enc\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        x = self.pos_enc(x)\n",
    "\n",
    "        x = self.encoder(x, mask=None)\n",
    "\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer_model(input_dim: int, timesteps: int, filter_size: int, output_size: int, num_layers: int, num_heads: int, num_classes: int, kernel_size_1: int, kernel_size_2: int, dropout: float):\n",
    "    # Conv1D Block\n",
    "    conv = Conv1DBlock(input_dim, filter_size, output_size, kernel_size_1, kernel_size_2)\n",
    "\n",
    "    # Positional Encoding\n",
    "    pos_enc = PositionalEncoding(timesteps, output_size, dropout)\n",
    "\n",
    "    # Encoder\n",
    "    encoder_layers = []\n",
    "    for _ in range(num_layers):\n",
    "        encoder_self_attention_block = MultiHeadAttentionBlock(output_size, num_heads, dropout)\n",
    "        feed_forward_block = FeedForwardBlock(output_size, output_size * 4, dropout)\n",
    "        encoder_layer = EncoderBlock(output_size, encoder_self_attention_block, feed_forward_block, dropout)\n",
    "        encoder_layers.append(encoder_layer)\n",
    "    encoder = Encoder(output_size, nn.ModuleList(encoder_layers))\n",
    "\n",
    "    # Freezed first 3 layers\n",
    "    freezed_layers = [0, 1, 2]\n",
    "    for i in freezed_layers:\n",
    "        for param in encoder.layers[i].parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Classifier\n",
    "    classifier = ClassificationHead(output_size, num_classes)\n",
    "    \n",
    "    # Transformer model\n",
    "    model = TransformerBlock(conv, pos_enc, encoder, classifier)\n",
    "    \n",
    "    # Initialize the parameters\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformer_model(config, input_dim, timesteps):\n",
    "    model = build_transformer_model(\n",
    "        input_dim=input_dim,\n",
    "        timesteps=timesteps,\n",
    "        filter_size=config['filter_size'],\n",
    "        output_size=config['output_size'],\n",
    "        num_layers=config['num_layers'],\n",
    "        num_heads=config['num_heads'],\n",
    "        num_classes=config['num_classes'],\n",
    "        kernel_size_1=config['kernel_size_1'],\n",
    "        kernel_size_2=config['kernel_size_2'],\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Inference Function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def validate_model(model, val_loader, loss_fn, device, writer, global_step):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for validation\n",
    "        batch_iterator = tqdm(val_loader, desc=\"Validating\")\n",
    "        for batch in batch_iterator:\n",
    "            inputs = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted_labels = torch.max(outputs, 1) \n",
    "            correct_predictions += (predicted_labels == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "            batch_iterator.set_postfix({\n",
    "                \"val_loss\": f\"{loss.item():6.3f}\", \n",
    "                \"accuracy\": f\"{(correct_predictions / total_predictions):6.3f}\"\n",
    "            })\n",
    "\n",
    "    # Calculate the average validation loss and accuracy for this epoch\n",
    "    avg_val_loss = val_loss / total_predictions\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Log validation loss and accuracy to TensorBoard\n",
    "    writer.add_scalar('val loss', avg_val_loss, global_step)\n",
    "    writer.add_scalar('val accuracy', accuracy, global_step)\n",
    "    writer.flush()\n",
    "\n",
    "    return avg_val_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Prediction Function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def predict(model, input):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "\n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    probability_distribution = probabilities.squeeze().cpu().numpy()\n",
    "\n",
    "    return predicted_class, probability_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Main Training-Validation Loop Function</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from config import get_config, get_weights_file_path, latest_weights_file_path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "def train_model(config):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device {device}\")\n",
    "    if (device == \"cuda\"):\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n",
    "        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n",
    "    device = torch.device(device)\n",
    "\n",
    "    Path(config['model_folder']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    audio_files = get_audio_files_and_labels(dataset_dir)\n",
    "    x, y = load_and_preprocess_dataset(audio_files)\n",
    "\n",
    "    # # Checking the dataset size\n",
    "    # assert len(x) == len(y) == 12730, \"Dataset size mismatch!\"\n",
    "\n",
    "    # Train/Test split\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    x_val = torch.from_numpy(x_val).float()\n",
    "    y_train = torch.from_numpy(np.array(y_train)).long()\n",
    "    y_val = torch.from_numpy(np.array(y_val)).long()\n",
    "\n",
    "    # Move the tensors to device specified\n",
    "    x_train = x_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    x_val = x_val.to(device)\n",
    "    y_val = y_val.to(device)\n",
    "\n",
    "    # #? LOL WHAT\n",
    "    # x_train = torch.from_numpy(x).float()\n",
    "    # x_val = x_train\n",
    "    # y_train = torch.from_numpy(np.array(y)).long()\n",
    "    # y_val = y_train\n",
    "    \n",
    "    # Create Dataset and DataLoader\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, config['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    input_shape = x_train.shape[-1]\n",
    "    timesteps = x_train.shape[1]\n",
    "\n",
    "    model = get_transformer_model(config, input_shape, timesteps).to(device)\n",
    "    # Tensorboard\n",
    "    writer = SummaryWriter(config['experiment_name'])\n",
    "\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config['lr'])\n",
    "\n",
    "    initial_epoch = 0\n",
    "    global_step = 0\n",
    "    preload = config['preload']\n",
    "    model_filename = latest_weights_file_path(config) if preload == 'latest' else get_weights_file_path(config, preload) if preload else None\n",
    "    if model_filename:\n",
    "        print(f'Preloading model {model_filename}')\n",
    "        state = torch.load(model_filename)\n",
    "        model.load_state_dict(state['model_state_dict'])\n",
    "        initial_epoch = state['epoch'] + 1\n",
    "        optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "        global_step = state['global_step']\n",
    "    else:\n",
    "        print('No model to preload, starting from scratch')\n",
    "\n",
    "    y_train_cpu = y_train.to(\"cpu\")\n",
    "\n",
    "    y_train_np = y_train_cpu.numpy()\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight(\n",
    "        'balanced',\n",
    "        classes=np.unique(y_train_np),\n",
    "        y=y_train_np\n",
    "    )\n",
    "\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1, weight=class_weights_tensor).to(device)\n",
    "\n",
    "    for epoch in range(initial_epoch, config['epochs']):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        batch_iterator = tqdm(train_loader, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "        for batch in batch_iterator:\n",
    "\n",
    "            inputs = batch[0].to(device) \n",
    "            labels = batch[1].to(device) \n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss using a simple cross entropy\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
    "\n",
    "            # Log the loss\n",
    "            writer.add_scalar('train loss', loss.item(), global_step)\n",
    "            writer.flush()\n",
    "\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        # Run validation at the end of every epoch\n",
    "        validate_model(model, val_loader, loss_fn, device, writer, global_step)\n",
    "\n",
    "        # Save the model every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'global_step': global_step\n",
    "            }, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "config = get_config()\n",
    "train_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Prediction</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading model models/baseline_model/convtmodel_169.pt\n",
      "Audio File: ./12K-Sorted\\NoStutter\\WomenWhoStutter_100_25.wav\n",
      "Actual Label: NoStutter\n",
      "Predicted Class: NoStutter\n",
      "Probability Distribution: [0.09101424 0.00587998 0.45391983 0.18611157 0.22846724 0.03460718]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from config import get_config\n",
    "config = get_config()\n",
    "\n",
    "audio_files = get_audio_files_and_labels(dataset_dir)\n",
    "\n",
    "audio, label = audio_files[7777]\n",
    "\n",
    "input = preprocess_concat_audio(audio)\n",
    "\n",
    "input = torch.from_numpy(input).float()\n",
    "input = input.unsqueeze(0)\n",
    "\n",
    "input_shape = input.shape[-1]\n",
    "timesteps = input.shape[1]\n",
    "\n",
    "model = get_transformer_model(config, input_shape, timesteps)\n",
    "\n",
    "saved_model = 'models/baseline_model/convtmodel_169.pt'\n",
    "\n",
    "print(f'Preloading model {saved_model}')\n",
    "print(f\"Audio File: {audio}\")\n",
    "state = torch.load(saved_model)\n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "\n",
    "predicted_class, probabilities = predict(model, input)\n",
    "\n",
    "print(f\"Actual Label: {reversed_map.get(label)}\")\n",
    "print(f\"Predicted Class: {reversed_map.get(predicted_class)}\")\n",
    "print(f\"Probability Distribution: {probabilities}\")\n",
    "\n",
    "print(predicted_class)\n",
    "\n",
    "plot_probability_distribution(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
